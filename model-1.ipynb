{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1436057,"sourceType":"datasetVersion","datasetId":841381},{"sourceId":2256095,"sourceType":"datasetVersion","datasetId":1357563},{"sourceId":445645,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":361867,"modelId":382835}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport pandas as pd\nimport cv2\nimport gc\nimport numpy as np\nimport random\nimport imageio\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nfrom IPython.display import display\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport keras_tuner as kt\nfrom tensorflow.keras.models import load_model\nfrom IPython.display import Image as DisplayImage\nfrom io import BytesIO\nimport seaborn as sn\nfrom sklearn import metrics\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.regularizers import l2\nfrom kerastuner.tuners import RandomSearch\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport seaborn as sns\nfrom tensorflow.keras.callbacks import Callback","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#full ucf50\n'''class CFG:\n    epochs = 20\n    batch_size = 8\n    classes = [\"BaseballPitch\", \"Basketball\", \"BenchPress\", \"Biking\", \"Billiards\", \"BreastStroke\",\n               \"CleanandJerk\", \"Diving\", \"Drumming\", \"Fencing\", \"GolfSwing\", \"HighJump\",\n               \"HorseRace\", \"HorseRiding\", \"HulaHoop\", \"JavelinThrow\", \"JugglingBalls\",\n               \"JumpRope\", \"JumpingJack\", \"Kayaking\", \"Lunges\", \"MilitartParade\",\n               \"Mixing\", \"Nunchucks\", \"PizzaTossing\", \"PlayingGuitar\", \"PlayingPiano\",\n               \"PlayingTabla\", \"PlayingViolin\", \"PoleVault\", \"PommelHorse\", \"PullUps\",\n               \"Punch\", \"PushUps\", \"RockClimbingIndoor\", \"RopeClimbing\", \"Rowing\", \n               \"SalsaSpin\", \"SkateBoarding\", \"Skiing\", \"Skijet\", \"SoccerJuggling\", \n               \"Swing\", \"TaiChi\", \"TennisSwing\", \"ThrowDiscus\", \"TrampolineJumping\", \n               \"VolleyballSpiking\", \"WalkingWithDog\", \"YoYo\"]'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#full ucf101\nclass CFG:\n    epochs = 20\n    batch_size = 8\n    classes = [\"ApplyEyeMakeup\", \"ApplyLipstick\", \"Archery\", \"BabyCrawling\", \n               \"BalanceBeam\", \"BandMarching\", \"BaseballPitch\", \"Basketball\", \n               \"BasketballDunk\", \"BenchPress\", \"Biking\", \"Billiards\", \n               \"BlowDryHair\", \"BlowingCandles\", \"BodyWeightSquats\", \"Bowling\", \n               \"BoxingPunchingBag\", \"BoxingSpeedBag\", \"BreastStroke\", \"BrushingTeeth\", \n               \"CleanAndJerk\", \"CliffDiving\", \"CricketBowling\", \"CricketShot\", \n               \"CuttingInKitchen\", \"Diving\", \"Drumming\", \"Fencing\", \"FieldHockeyPenalty\", \n               \"FloorGymnastics\", \"FrisbeeCatch\", \"FrontCrawl\", \"GolfSwing\", \"Haircut\", \n               \"HammerThrow\", \"Hammering\", \"HandstandPushups\", \"HandstandWalking\", \n               \"HeadMassage\", \"HighJump\", \"HorseRace\", \"HorseRiding\", \"HulaHoop\", \n               \"IceDancing\", \"JavelinThrow\", \"JugglingBalls\", \"JumpRope\", \"JumpingJack\", \n               \"Kayaking\", \"Knitting\", \"LongJump\", \"Lunges\", \"MilitaryParade\", \"Mixing\", \n               \"MoppingFloor\", \"Nunchucks\", \"ParallelBars\", \"PizzaTossing\", \"PlayingGuitar\", \n               \"PlayingPiano\", \"PlayingTabla\", \"PlayingViolin\", \"PlayingCello\", \"PlayingDaf\", \n               \"PlayingDhol\", \"PlayingFlute\", \"PlayingSitar\", \"PoleVault\", \"PommelHorse\", \n               \"PullUps\", \"Punch\", \"PushUps\", \"Rafting\", \"RockClimbingIndoor\", \n               \"RopeClimbing\", \"Rowing\", \"SalsaSpins\", \"ShavingBeard\", \"Shotput\", \n               \"SkateBoarding\", \"Skiing\", \"Skijet\", \"SkyDiving\", \"SoccerJuggling\", \n               \"SoccerPenalty\", \"StillRings\", \"SumoWrestling\", \"Surfing\", \"Swing\", \n               \"TableTennisShot\", \"TaiChi\", \"TennisSwing\", \"ThrowDiscus\", \n               \"TrampolineJumping\", \"Typing\", \"UnevenBars\", \"VolleyballSpiking\", \n               \"WalkingWithDog\", \"WallPushups\", \"WritingOnBoard\", \"YoYo\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Pad and resize an image from a video\ndef format_frames(frame, output_size):\n  frame = tf.image.convert_image_dtype(frame, tf.float32)\n  frame = tf.image.resize_with_pad(frame, *output_size)\n  return frame\n\n#Creates frames from each video file present for each category\ndef frames_from_video_file(video_path, n_frames, output_size = (32,32), frame_step = 5): #frame_step = 15\n  # Read each video frame by frame\n  result = []\n  src = cv2.VideoCapture(str(video_path))  \n\n  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n\n  need_length = 1 + (n_frames - 1) * frame_step\n\n  if need_length > video_length:\n    start = 0\n  else:\n    max_start = video_length - need_length\n    start = random.randint(0, max_start + 1)\n\n  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n  # ret is a boolean indicating whether read was successful, frame is the image itself\n  ret, frame = src.read()\n  result.append(format_frames(frame, output_size))\n\n  for _ in range(n_frames - 1):\n    for _ in range(frame_step):\n      ret, frame = src.read()\n    if ret:\n      frame = format_frames(frame, output_size)\n      result.append(frame)\n    else:\n      result.append(np.zeros_like(result[0]))\n  src.release()\n  result = np.array(result)[..., [2, 1, 0]]\n\n  return result\n\n# Create a list to store the frames\ndef to_gif(images):\n    frames = []\n    \n    # Convert and append each image as a frame\n    for image in images:\n        # Assuming the images are numpy arrays\n        converted_image = Image.fromarray(np.clip(image * 255, 0, 255).astype(np.uint8))\n        frames.append(converted_image)\n    \n    # Create an in-memory file object\n    gif_bytes = BytesIO()\n    \n    # Save frames as an animated GIF\n    frames[0].save(gif_bytes, format='GIF', append_images=frames[1:], save_all=True, duration=100, loop=0)\n            \n    display_gif(gif_bytes.getvalue())\n\n# Display the animated GIF\ndef display_gif(data):\n    display(DisplayImage(data=data, format='gif'))\n    #with open(\"test2.gif\", \"wb\") as png:\n    #    png.write(data)\n\nfile_paths = []\ntargets = []\nfor i, cls in enumerate(CFG.classes):\n    #full ucf50\n    #sub_file_paths = glob.glob(f\"/kaggle/input/ucf50/UCF50/{cls}/**.avi\")\n    sub_file_paths = glob.glob(f\"/kaggle/input/ucf101/UCF101/UCF-101/{cls}/**.avi\")\n    file_paths += sub_file_paths\n    targets += [i] * len(sub_file_paths)\n\nfeatures = []\nfor file_path in tqdm(file_paths):\n    if file_path == \"/kaggle/input/ucf11dataset/UCF11_updated_mpg/basketball/v_shooting_25/v_shooting_25_06.mpg\":\n        continue\n    features.append(frames_from_video_file(file_path, n_frames = 30))  #50 \nto_gif(features[0])\nfeatures = np.array(features)\nprint(len(features))\n\ntrain_features, rest_features, train_targets, rest_targets = train_test_split(features, targets, test_size=0.3, random_state=42)\nval_features, test_features, val_targets, test_targets = train_test_split(rest_features, rest_targets, test_size=0.7, random_state=42)\n\nprint(\"for training: \",len(train_features),len(train_targets))\nprint(\"for validation: \",len(val_features),len(val_targets))\nprint(\"for testing: \",len(test_features),len(test_targets))\nto_gif(val_features[2])\nprint(val_targets[2])\ndel features\ndel rest_features\ndel rest_targets\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_features, train_targets)).shuffle(CFG.batch_size * 4).batch(CFG.batch_size).cache().prefetch(tf.data.AUTOTUNE)\nvalid_ds = tf.data.Dataset.from_tensor_slices((val_features, val_targets)).batch(CFG.batch_size).cache().prefetch(tf.data.AUTOTUNE)\ntest_ds =  tf.data.Dataset.from_tensor_slices((test_features, test_targets)).batch(CFG.batch_size).cache().prefetch(tf.data.AUTOTUNE)\ndel train_targets\ndel train_features\ndel val_features\ndel val_targets\ndel test_features\ndel test_targets\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ****Model 1****","metadata":{}},{"cell_type":"code","source":"'''\ndef build_model(hp):\n    model = tf.keras.Sequential()\n    model.add(tf.keras.Input(shape=(30, 32, 32, 3)))  # Fixed input shape\n    \n    # Tune Conv3D layers\n    for i in range(hp.Int('num_conv_layers', 3, 5)):\n        model.add(tf.keras.layers.Conv3D(\n            filters=hp.Int(f'filters_{i}', min_value=32, max_value=256, step=10),\n            kernel_size=(3, 3, 3),\n            strides=1,\n            padding='same',\n            activation='relu'\n        ))\n        model.add(tf.keras.layers.BatchNormalization())\n        model.add(tf.keras.layers.MaxPool3D(\n            pool_size=(2, 2, 2),\n            strides=2,\n            padding='same'\n        ))\n        \n        if hp.Choice(f'add_dropout_{i}', [True, False]):\n            model.add(tf.keras.layers.Dropout(\n                rate=hp.Float(f'dropout_rate_{i}', 0.1, 0.5)\n            ))\n    \n    model.add(tf.keras.layers.Flatten())\n    \n    # Tune dense layer\n    model.add(tf.keras.layers.Dense(\n        units=hp.Int('dense_units', min_value=128, max_value=512, step=5),\n        activation='relu'\n    ))\n    \n    model.add(tf.keras.layers.Dense(len(CFG.classes), activation='softmax'))\n    \n    # Tune learning rate\n    learning_rate = hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='log')\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=['accuracy']\n    )\n    return model\n\n# Initialize Hyperband tuner\ntuner = kt.Hyperband(\n    build_model,\n    objective='val_accuracy',\n    max_epochs=50,\n    factor=15,\n    directory='hyperband_tuning',\n    project_name='ucf50_action_recognition'\n)\n\n# Callbacks\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1\n)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\ntuner.search(\n    train_ds,\n    epochs=50,\n    validation_data=valid_ds,\n    callbacks=[early_stop, checkpoint]\n)\n\nbest_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# Build and train best model\nmodel = build_model(best_hp)\n\nfilename='histroylog.csv'\nhistory_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n\nmodel.summary()\n\n# Fit best model manually and log history\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=50,\n    callbacks=[checkpoint, early_stop, history_logger]\n)\n\n# Convert training history to DataFrame\ndf = pd.DataFrame(history.history)\n\n# Plot training vs validation loss and accuracy\nfor metrics in [(\"loss\", \"val_loss\"), (\"accuracy\", \"val_accuracy\")]:\n    df[list(metrics)].plot()\n    plt.title(f'{metrics[0]} vs {metrics[1]}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.show()\n\ny_true = []\ny_pred = []\n\n# Loop over test dataset\nfor x_batch, y_batch in test_ds:\n    # Predict probabilities\n    preds = model.predict(x_batch, verbose=0)\n    \n    # Get predicted class indices\n    pred_classes = np.argmax(preds, axis=1)\n    \n    y_pred.extend(pred_classes)\n    y_true.extend(y_batch.numpy())  # labels are already integers\n\nprint(classification_report(y_true, y_pred))\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"viridis\")  # or use cmap=\"plasma\", \"inferno\", etc.\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''test_loss, test_acc = model.evaluate(test_ds)\nprint(f\"\\nTest accuracy: {test_acc:.3f}\")'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ****Model 2****","metadata":{}},{"cell_type":"code","source":"'''\ndef build_model(hp):\n    model = tf.keras.Sequential()\n    model.add(tf.keras.Input(shape=(30, 32, 32, 3)))  # Fixed input shape\n    \n    # Tune Conv3D layers\n    for i in range(hp.Int('num_conv_layers', 3, 5)):\n        model.add(tf.keras.layers.Conv3D(\n            filters=hp.Int(f'filters_{i}', min_value=32, max_value=256, step=10),\n            kernel_size=(3, 3, 3),\n            strides=1,\n            padding='same',\n            activation='relu'\n        ))\n        model.add(tf.keras.layers.BatchNormalization())\n        model.add(tf.keras.layers.MaxPool3D(\n            pool_size=(2, 2, 2),\n            strides=2,\n            padding='same'\n        ))\n        \n        if hp.Choice(f'add_dropout_{i}', [True, False]):\n            model.add(tf.keras.layers.Dropout(\n                rate=hp.Float(f'dropout_rate_{i}', 0.1, 0.5)\n            ))\n    \n    model.add(tf.keras.layers.Flatten())\n    \n    # Tune dense layer\n    model.add(tf.keras.layers.Dense(\n        units=hp.Int('dense_units', min_value=128, max_value=512, step=10),\n        activation='relu'\n    ))\n    \n    model.add(tf.keras.layers.Dense(len(CFG.classes), activation='softmax'))\n    \n    # Tune learning rate\n    learning_rate = hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='log')\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=['accuracy']\n    )\n    return model\n\n# Initialize Bayesian Optimization tuner\ntuner = kt.BayesianOptimization(\n    build_model,\n    objective='val_accuracy',\n    max_trials=20,  # Maximum number of trials to run\n    num_initial_points=10,  # Random exploration before Bayesian optimization\n    directory='bayesian_tuning',\n    project_name='ucf50_action_recognition'\n)\n\n# Callbacks\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"best_model.h5\", monitor=\"val_accuracy\", mode=\"max\",\n    save_best_only=True, verbose=1\n)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\n# Perform hyperparameter search\ntuner.search(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=50,\n    callbacks=[checkpoint, early_stop]\n)\n\n# Get best model\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# Evaluate on test set\n#test_loss, test_acc = best_model.evaluate(test_ds)\n#print(f\"\\nTest accuracy: {test_acc:.3f}\")\n\n# Optional: Retrain best model with full training data\nhistory = best_model.fit(tf.data.Dataset.concatenate(train_ds, valid_ds), \n               epochs=CFG.epochs*2, validation_data=valid_ds)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Initialize lists to store true and predicted labels\ny_true = []\ny_pred = []\n\n# Loop over test dataset\nfor x_batch, y_batch in test_ds:\n    # Predict probabilities\n    preds = best_model.predict(x_batch, verbose=0)\n    \n    # Get predicted class indices\n    pred_classes = np.argmax(preds, axis=1)\n    \n    y_pred.extend(pred_classes)\n    y_true.extend(y_batch.numpy())  # labels are already integers\n\nprint(classification_report(y_true, y_pred))\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"viridis\")  # or use cmap=\"plasma\", \"inferno\", etc.\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\ntest_loss, test_acc = best_model.evaluate(test_ds)\nprint(f\"\\nTest accuracy: {test_acc:.3f}\")\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ****Model 3****","metadata":{}},{"cell_type":"code","source":"\ndef build_model(hp):\n    inputs = layers.Input(shape=(30, 32, 32, 3))  # (frames, height, width, channels)\n\n    # Conv3D Block 1\n    x = layers.Conv3D(\n        filters=hp.Int(\"conv3d_filters_1\", 32, 96, step=16),\n        kernel_size=(3, 3, 3),\n        activation=\"relu\",\n        padding=\"same\",\n        kernel_regularizer=l2(hp.Choice(\"l2_reg\", [1e-4, 1e-5]))\n    )(inputs)\n    x = layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n    x = layers.BatchNormalization()(x)\n\n    # Conv3D Block 2\n    x = layers.Conv3D(\n        filters=hp.Int(\"conv3d_filters_2\", 64, 128, step=16),\n        kernel_size=(3, 3, 3),\n        activation=\"relu\",\n        padding=\"same\",\n        kernel_regularizer=l2(hp.Choice(\"l2_reg\", [1e-4, 1e-5]))\n    )(x)\n    x = layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n    x = layers.BatchNormalization()(x)\n\n    # Conv3D Block 3\n    x = layers.Conv3D(\n        filters=hp.Int(\"conv3d_filters_3\", 64, 128, step=16),\n        kernel_size=(3, 3, 3),\n        activation=\"relu\",\n        padding=\"same\",\n        kernel_regularizer=l2(hp.Choice(\"l2_reg\", [1e-4, 1e-5]))\n    )(x)\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Reshape((1, -1))(x)\n\n    # Bidirectional LSTM\n    lstm_units = hp.Int(\"lstm_units\", 128, 512, step=64)\n    x = layers.Bidirectional(\n        layers.LSTM(lstm_units, return_sequences=True)\n    )(x)\n\n    # Attention Mechanism\n    attention = layers.Dense(1, activation='tanh')(x)\n    attention = layers.Flatten()(attention)\n    attention = layers.Activation('softmax')(attention)\n    attention = layers.RepeatVector(lstm_units * 2)(attention)\n    attention = layers.Permute([2, 1])(attention)\n    x = layers.multiply([x, attention])\n    x = layers.Lambda(lambda xin: tf.reduce_sum(xin, axis=1))(x)\n\n    # Fully Connected Layer\n    x = layers.Dense(\n        units=hp.Int(\"dense_units\", 128, 512, step=64),\n        activation='relu',\n        kernel_regularizer=l2(hp.Choice(\"l2_reg\", [1e-4, 1e-5]))\n    )(x)\n    x = layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1))(x)\n\n    # Output Layer\n    outputs = layers.Dense(len(CFG.classes), activation='softmax')(x)\n\n    model = models.Model(inputs, outputs)\n\n    # Optimizer\n    optimizer_choice = hp.Choice(\"optimizer\", [\"adam\", \"adamw\", \"rmsprop\"])\n    learning_rate = hp.Choice(\"learning_rate\", [1e-3, 5e-4, 3e-4, 1e-4, 1e-5])\n\n    if optimizer_choice == \"adam\":\n        optimizer = tf.keras.optimizers.Adam(learning_rate)\n    elif optimizer_choice == \"adamw\":\n        optimizer = tf.keras.optimizers.AdamW(learning_rate)\n    elif optimizer_choice == \"rmsprop\":\n        optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    model.compile(\n        optimizer=optimizer,\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\n# Define tuner\ntuner = RandomSearch(\n    build_model,                       # your model-building function\n    objective='val_accuracy',\n    max_trials=6, #20,                    # total different combinations to try\n    #executions_per_trial=1,           # number of times to train each combination\n    directory='video_model_tuning',\n    project_name='3dcnn_lstm_attention'\n)\n\n# Optional: early stopping and LR reduction\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n# Define callbacks\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1\n)\n# Run tuner search\ntuner.search(\n    train_ds,\n    epochs=50,\n    validation_data=valid_ds,\n    callbacks=[early_stop, reduce_lr, checkpoint]  # add all callbacks\n)\n\nbest_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# Build and train best model\nmodel = build_model(best_hp)\n\nmodel.summary()\n\n\n\n# Fit best model manually and log history\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=50,\n    callbacks=[early_stop, reduce_lr, checkpoint]\n)\n\n# Convert training history to DataFrame\ndf = pd.DataFrame(history.history)\n\n# Plot training vs validation loss and accuracy\nfor metrics in [(\"loss\", \"val_loss\"), (\"accuracy\", \"val_accuracy\")]:\n    df[list(metrics)].plot()\n    plt.title(f'{metrics[0]} vs {metrics[1]}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.show()\n\n# Step 1: Get true and predicted labels\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    preds = model.predict(images)\n    y_true.extend(labels.numpy())               # Sparse integer labels\n    y_pred.extend(np.argmax(preds, axis=1))     # Predicted class index\n\n# Step 2: Compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Step 3: Plot using seaborn\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=False, fmt=\"d\", cmap='viridis')  # You can change cmap if desired\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\ntest_loss, test_acc = model.evaluate(test_ds)\n\nprint(f\"Test Loss:{test_loss} Testing Accuracy:{test_acc}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ****Model 4****","metadata":{}},{"cell_type":"code","source":"'''\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport tensorflow_addons as tfa\n\n\ndef build_enhanced_model(input_shape=(30, 32, 32, 3), num_classes=50):\n    inputs = tf.keras.Input(shape=input_shape)\n\n    # Spatial Feature Extraction\n    x = tf.keras.layers.Conv3D(32, (3,3,3), activation='relu', padding='same')(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPool3D((1,2,2))(x)\n\n    x = tf.keras.layers.Conv3D(64, (3,3,3), activation='selu', padding='same')(x)\n    x = tf.keras.layers.SpatialDropout3D(0.25)(x)\n    x = tf.keras.layers.MaxPool3D((1,2,2))(x)\n\n    # Residual Block\n    residual = tf.keras.layers.Conv3D(128, (1,1,1), padding='same')(x)\n    x = tf.keras.layers.Conv3D(128, (3,3,3), activation='selu', padding='same')(x)\n    x = tf.keras.layers.Add()([x, residual])\n    x = tf.keras.layers.MaxPool3D((1,2,2))(x)\n\n    # Temporal Modeling\n    x = tf.keras.layers.Reshape((30, 4*4*128))(x)\n\n    # Bidirectional GRU (reduced size)\n    x = tf.keras.layers.Bidirectional(\n        tf.keras.layers.GRU(192, return_sequences=True, \n                            kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n    )(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n\n    # Attention with additional dropout\n    attn = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n    x = tf.keras.layers.Concatenate()([x, attn])\n    x = tf.keras.layers.LayerNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n\n    # Classification Head\n    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n    x = tf.keras.layers.Dense(256, activation='selu',\n                              kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n\n    model = tf.keras.Model(inputs, outputs)\n\n    # Cyclical Learning Rate with extended step size\n    clr = tfa.optimizers.CyclicalLearningRate(\n        initial_learning_rate=1e-4,\n        maximal_learning_rate=1e-3,\n        step_size=3000,\n        scale_fn=lambda x: 1 / (2. ** (x - 1))\n    )\n\n    optimizer = tfa.optimizers.AdamW(\n        learning_rate=clr,\n        weight_decay=1e-4,\n        clipnorm=1.0\n    )\n\n    model.compile(\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        optimizer=optimizer,\n        metrics=['accuracy']\n    )\n\n    return model\n\n\n\n# Initialize model\nmodel = build_enhanced_model()\n\nmodel.summary()\n\ncallbacks = [\n    #tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True, monitor='val_accuracy'),\n    tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n]\nhistory = \"\"\nhistory = model.fit(train_ds, validation_data=valid_ds, epochs=50, callbacks=callbacks)\n\nmodel.load_weights(\"best_model.h5\")\n\nfor metrics in [(\"loss\", \"val_loss\"), (\"accuracy\", \"val_accuracy\")]:\n    pd.DataFrame(history.history, columns=metrics).plot()\n    plt.show()\n\ntest_loss, test_acc = model.evaluate(test_ds)\n\nprint(f\"Test Loss:{test_loss} Testing Accuracy:{test_acc}\")\n\n# Step 1: Get true and predicted labels\ny_true = []\ny_pred = []\n\nfor images, labels in test_ds:\n    preds = model.predict(images)\n    y_true.extend(labels.numpy())               # Sparse integer labels\n    y_pred.extend(np.argmax(preds, axis=1))     # Predicted class index\n\n# Step 2: Compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Step 3: Plot using seaborn\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=False, fmt=\"d\", cmap='viridis')  # You can change cmap if desired\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''import tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nimport matplotlib.pyplot as plt\n\n# Load the model\nmodel = tf.keras.models.load_model(\"/kaggle/input/model2h5/keras/default/1/best_model.h5\")\n\n# Display a summary in console\nmodel.summary()\n\n# Plot and save model architecture as an image\nplot_model(model, to_file=\"model_architecture.png\", show_shapes=True, show_layer_names=True)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
